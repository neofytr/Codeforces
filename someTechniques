1. In questions that have the count of somethings changing when an operation is done and the total number of somethings remain constant, check how the parity of the count of things changes after an operation

2. In questions in which we can perform any operation from a group of operations, one after other, there is usually an optimal order for the
application of these operations (i.e., something like all operation 1s must occur before any operation 2s and so on) (see random/gettingZero)

3. For any x > 1, __builtin_ctzll(x) is the power of 2 in the prime factorization of x

4. If n is odd and >= 3, then
n, n - 1 and n - 2 have no prime
factors in common and
LCM(n, n - 1, n - 2) = n * (n - 1) * (n - 2)

5. For n >= 2, gcd(n, n - 1) = 1

6. Let x >= 1
Then, there can be atmost 1 number in the sequence

x, x + 1, x + 2, ..., x + (r - 1)

for some r >= 1 that is divisible by a number >= r

7. Count/Find triplets 1 <= i < j < k <= n that satisfy some conditions in O(n^2)

for (int k = 2; k <= n - 1; k++) {
	// iterate through [1, k - 1] to choose a suitable i

	// iterate through [k + 1, n] to choose a suitable j

	// check if (i, j, k) is a suitable pair
}

Thus, if we have to find a triplet, fix the middle one and solve two independent problems (if possible)

8. Let n >= 2
Let a1, a2, ..., an is a sequence of integers

If a1 <= an, then there are
two consecutive elements x, y
of the sequence such that x <= y

9. Let p(x1, y1) and q(x2, y2) be two points on a line y = mx + c.

Then, distance(p, q) = |x2 - x1| * root(1 + m * m)

For any integral m != 0, distance(p, q) is always irrational

10. For two distinct points P and Q in a plane to not have integral distance between them, it's necessary for them to be have different rows or different columns

11. For constructive questions, say we have to construct the maximal set satisfying some conditions, we can adopt the following approach:

i. Get an upper bound on the size of the set
ii. Do something to construct a set of that size

12. For x >= 0

i. floor(x / 2) = x >> 1
ii. ceil(x / 2) = (x >> 1) + (x & 1)

13.

Consider a sorted array v[1, n]

Let f(r) = |r - v[1]| + |r + 1 - v[2]| + ... |r + n - 1 - v[n]|

         = |v[1] - (r + 0)| + ... + |v[n] - (r + (n - 1))|

We can calculate this in O(log(n)) with O(n) precomputation as follows:

1. Construct an array s[1, n] such that

s[i] = v[i] - (i - 1) for 1 <= i <= n

3. Construct the prefix array of s, say p[0, n]

p[0] = 0 and p[r] = p[r - 1] + s[r] for 1 <= r <= n

2. Find the first index k in the array v[1, n] such that v[k] >= r

If such a k does not exist, then
f(r) = r * n - p[n]

If k == 1, then f(r) = p[n] - r * n

Otherwise,

f(r) = (p[n] - p[k - 1]) - r * (n - k + 1) + r * (k - 1) - (p[k - 1])

14.

Let n >= 1
Let S = {1, 2, ..., n}
Let A = {r is a natural number such that 1 <= r <= n * (n + 1) / 2}

Then, for any a in A, there is a subset s of S such that sum(s) = a
Also, there is no subset s of S such that
sum(s) > n * (n + 1) / 2

15.

Let n >= 3
Let l1, l2, ... , ln be positive integers

A polygon with n sides can be formed with
these integers as its side lengths iff

2 * max(l1, l2, ..., ln) <= l1 + l2 + ... + ln

, i.e, no side-length is greater than all the other side-lengths combined

16. In a problem where we are to count
the number of pairs of indexes (i, j) where 1 <= i < j <= n in an array arr[1, n] satisfying some condition, we can permute (usually, the permutation of the array used is the sorted one) the array beforehand and solve the problem if

i. Condition depends on values, not positions
ii. The number of pairs is invariant under the permutation
iii. Counting pairs/combinations/subsets
iv. Answer is unchanged by reordering (permutation invariant)

We cannot permute the array if

i. Problem involves subarrays/prefixes/suffixes
ii. Ordering of the elements matters
iii. Distance/position constraints are essential

16.

Let k >= 0

Let A[1, n] and B[1, m] be two integer arrays such that

0 <= A[r] < 2^k for 1 <= r <= n

Let f[s] = Summation from r = 1 to n of (A[r] ^ B[s]) for 1 <= s <= m

Suppose we want to find max(f[s] for 1 <= s <= m) in O(n + m)

We can do this as follows:

vector<int> bit(k);
for (int r = 1; r <= n; r++)
	for (int b = 0; b <= k - 1; b++)
		if (A[r] & (1 << b)) bit[b]++;

// We can now calculate each f[s] for 1 <= s <= m in O(1) now after this precomputation that is done in O(n)

int maxi = LLONG_MIN;
for (int r = 1; r <= m; r++) {
	int sum = 0;
	for (int b = 0; b <= k - 1; b++)
		if (B[r] & (1 << b)) sum += bit[b] * (1 << b);
		else sum += (n - bit[b]) * (1 << b)
}

17.

Let x >= 1
Let z is the smallest power of two >= x

Then x ^ y, for y >= 1 and y != x, divides y implies that y <= z - 1

18.

Let A[1, n] and B[1, k] are sorted
array of integers

Let f: A -> B

Suppose we are to find an assignment f such that

1. summation |A[r] - B[f[r]]| for 1 <= r <= n is minimized

or

2. max(|A[r] - B[f[r]]| for 1 <= r <= n) is minimized

Then, it is not optimal to assign in a crossed manner, i.e,

If we assign B[j] to some A[r], then, it is not optimal to assign A[r + 1] to any B[s] for s < j

19. Chicken McNugget Theorem

If you have two positive integers a and b that are coprime (that is, gcd(a, b) = 1), then, the largest
integer that cannot be written in the form ax + by, where x and y are non-negative integers, is ab - a - b
After this number, every larger number is representable

20.

Let f(x) = 11...1 (total of x ones)
Then, for any x >= 2, f(x) = 11 * a + 111 * b for some non-negative integers a and b

Rough Proof:

There are three possible cases for x:

1. x = 3 * r for some r >= 1
Then f(x) = 111 * pw(10, x - 3) + 111 * pw(10, x - 6) ... + 111 * pw(10, 0) = 111 * y for some y >= 0

2. x = 3 * r + 1 = 3 * (r - 1) + 4 for r >= 2
Then f(x) = 111 * pw(10, x - 3) + .. + 111 * pw(10, 4) + 11 * 100 + 11 = 111 * a + 11 * b for some a, b >= 0

3. x = 3 * r + 2
Then f(x) = 111 * pw(10, x - 3) + ... + 111 * pw(10, 2) + 11 * 100 = 111 * a + 11 * b for some a, b >= 0

21.

Let n >= 2
Let arr[1, n] be an array of non-negative integers

Suppose we have to partition arr into consecutive subarrays such that the XOR of all the subarrays are equal.
A partition with 1 subarray is always possible (the trivial partition {{1, 2, ..., n}})

Suppose we need to have the number of partitions >= 2
Let p[0] = 0 and p[r] = p[r - 1] ^ arr[r] for 1 <= r <= n

If p[n] = 0, then we can always partition arr[1, n] into two subarrays with equal XORs ->
{{1, ..., r}, {r + 1, ..., n}} where the XORs of both the subarrays are equal
Such two subarrays always exist since if the XOR of some numbers is 0, then its possible iff the numbers are equal
And since p[n] = arr[1] ^ ... ^ arr[n] = 0, then we will always have p[n] = x ^ x where the first x is the xor of some prefix, and the
second x is xor of the rest of the array

If p[n] > 0, then, no even length partition exists since XOR of an equal number of even things is zero
So if the array can be partitioned, it will have an odd length partition
Now, since the XORs of the partitioned subarrays are equal and the partitioned subarrays are odd in number,
the XORs of these partitioned subarrays = p[n]
So, we can check if such a partition exists by the following code:

int cnt = 0, l = 1, r = 1;
while (l <= r) {
    l = r;
    while (r <= n && (p[r] ^ p[l - 1] != p[n]) r++;
    if (r <= n && p[r] ^ p[l - 1] == p[n]) cnt++;
    l = r + 1;
}

if (cnt >= 1) return true;
else return false;

22.

When during thinking of a transition for dp[r], you find that the transition involves dependency
on values of some dp[r + l] where l > 0, then, think of push-dp or recursion to solve the problem.

23. String DP Patterns

Four things to remember:

The "prefix to prefix" pattern (comparing beginnings of both strings) is the foundation of all string DP.

1. String DP compares prefixes. dp[i][j] relates prefix of string A to prefix of string B
2. Match v/s operate. When characters match, you get a free transition.
3. Three choices become one min. Replace, delete, insert map to three neighbors.
4. Base cases are edge strings. Empty-to-something costs the length.

For example consider the problem Edit Distance.
Let A[1, n] and B[1, m] be the two strings

We define dp[i][j] is the minimum number of operations required to convert A[1, i] into B[1, j]
Here are the transitions

dp[0][0] = 0
dp[0][j] = j for all 1 <= j <= m
dp[i][0] = i for all 1 <= i <= n

dp[i][j] = dp[i - 1][j - 1] if A[i] = B[j]
         = min(dp[i - 1][j] + 1, dp[i][j - 1] + 1, dp[i - 1][j - 1] + 1) otherwise

The final answer is dp[n][m]

24. Resource Tracking DP
dp[i][j] is the answer after i steps using j of some resource

25. Grid DP
dp[i][j] is the answer for cell at row i, column j

26. String DP
dp[i][j] is the answer comparing first i characters of one string to first j of another

27. Ordered Inclusion-Exclusion using DP (First-violation DP pattern)

This technique applies to problems of the following type:
1. We want to count objects (paths, sequences, walks, strings, processes, etc.)
2. Objects are built step by step (or move monotonically)
3. There are forbidden states / events
4. The total state space is too large for naive DP
5. Direct inclusion-exclusion over forbidden sets is exponential and impossible

The technique relies on one crucial property: Every invalid object has a unique earliest violation
This is the entire foundation. It matters because if each bad object can be charged to exactly one first
bad event, then we can subtract bad objects once and only once. This avoid exponential inclusion-exclusion.

Let:
Object = things we want to count
States = ordered checkpoints / events / positions
State order = 0 < 1 < 2 < ... < K

For this technique to work, the following property must be satisfied: If state j > i, then we cannot encounter state j and then state i afterwards

We define dp[r] = number of objects that reach state i without violating any forbidden state < i for 1 <= i <= K
For each state i, we can compute total(i) = number of ways to reach state i ignoring all constraints

Take any invalid object that reaches state i. Because of monotonicity/ordering, it must violate constraints
for the first time at some state j < i. This j is unique, well-defined and the earliest violation.

This allows a partition of invalid objects: Invalid objects reaching i = union of objects whose first violation is at j, for all j < i
This partition is disjoint.

An object whose first violation is at j has two parts:
1. A valid object from start to j
2. An unconstrained continuation from j to i

Why the first part is valid: because j is the first violation
Therefore, the number of such objects is dp[j] * ways(j -> i)

This is the key multiplicative structure.

Putting everything together:

dp[i] = total(i)
for all j < i: dp[i] -= dp[j] * ways(j -> i)

This is the final transition.

28. Ordered IE DP
Suppose we have some states a, s1, s2, ..., sk < b that are distinct
Suppose we are to find the number of paths from state a to state b such that we don't pass through any of
the states s1, ..., sk.

This can be done using IE but that is exponential in k. This can be reduced to O(k^2) using the following technique.

This technique works if there is an ordering among the states a < s1 < ... < sk < b such that we cannot visit a state j
first and then visit some state i < j

Let 1 <= r <= k
Let dp[r] = number of paths from state a to state sr that do not pass through any state si where i < r
Now dp[r] = total_paths(a, sr) - (paths from state a to state sr that pass through some state si where i < r)

Let a path from state a to state sr be called invalid if it passes through some state si where i < r
Thus, dp[r] = total_paths(a, sr) - (number of invalid paths from state a to state sr)

Let p is an invalid path from state a to state sr. Due to the above property, the path p has a unique
transition state st for 1 <= t <= r - 1 such that p does not pass through any state sk where k < t and p
passes through state st.

Let Ak = set of all paths that have their transition state st = k
Now |Ak| = dp[k] * total_paths(st, sr)

Now, any invalid path from state a to state sr has a transition state st for 1 <= t <= r - 1. Thus
the set of all such invalid paths = Union of Ak for 1 <= k <= r - 1

Also, any Ai and Aj for i < j are disjoint since for any path p1 in Ai and p2 in Aj, p1 and p2 are different
since p1 passes through si and p2 cannot pass through si since j > i.

Thus, the number of such invalid paths = summation of |Ak| for 1 <= k <= r - 1

Thus, dp[r] = total_ways(a, sr) - summation of (dp[k] * total_ways(sk, sr)) for 1 <= k <= r - 1, for 1 <= r <= k
For dp[b], just replace sr in the above formula by b

29. Reverse Inner Loop for DP Space Optimization

This technique applies to DP problems with the following structure:
You process items one by one, and for each item you update DP states that represent a resource limit, i.e, 0/1 knapsack-style DP

Canonical 2D DP formulation
Let:
i = number of items considered
s = resource used

Define dp[i][s] = best/possible using first i items with resource s
Transition: dp[i][s] = either dp[i - 1][s] or dp[i - 1][s - wi] + vi (choose max/OR/min depending on the problem)

Here, dp[i][*] depends only on dp[i - 1][*]

Why space optimization is possible?
Since row i depends only on row i-1, storing the entire table is wasteful

Space reduction options:
1. Use two arrays (prev, curr)
2. Use one array and overwrite carefully

This technique focuses on the second option

If you write dp[s] = max(dp[s], dp[s - w) you are:
1. reading from dp
2. writing to dp

So you must guarantee that dp[s - w] still represents the previous item, not the current one
If this is violated -> same item reused many times

Why forward iteration fails?
Forward Loop (WRONG for 0/1 problems)

for (int s = w; s <= S; s++)
    dp[s] = max(dp[s], dp[s - w])

What happens?
1. dp[s - w] may have already been updated using the current item
2. This allows multiple uses of the same item

Result: You accidentally implement unbounded knapsack

The reverse loop solution (key idea)
for (int s = S; s >= w; s--)
    dp[s] = max(dp[s], dp[s - w])

Since w >= 1, s - w <= s and thus uses results from the last item stored in [1, s - 1], which aren't
altered when we calculate dp[s] when iterating backwards. This is why the reverse loop works and is correct.

Why this works:
When iterating backwards:
1. s - w < s
2. Since we are going from high -> low, dp[s - w] is untouched in this iteration
3. So it still equals dp[i - 1][s - w]

General Structure

0/1 Knapsack DP template (1D)

initialize dp[0, S]
for each item (wt w, value v):
    for s = S down to w:
        dp[s] = combine(dp[s], dp[s - w], v)

Where combine = max, min, or, +, etc

Multidimensional Generalization:

If DP is: dp[i][a][b], you may compress the dimension i, but all resource dimensions must be iterated backwards
for a = A down to wa:
    for b = B down to wb:
        dp[a][b] = ...

If you compress a DP dimension and each choice is allowed only once, iterate resource dimensions backwards.
In 1D optimization, we iterate capacity in reverse to ensure each item is used at most once. Forward iteration would allow the same item to be picked multiple times in a single row.

30. Value-Based Knapsack

When one dimension of DP is too large, check if you can swap it with the answer.
Standard Knapsack: capacity as index, value as answer
Value-based Knapsack: value as index, weight as answer (then filer by capacity)

This swap works when the "large" dimension is what you'd normally index by, and the "small" dimension
(total value) can become the new index. Look at the constraints carefully; they often hint at which formulation
to use

31. If the dp transition looks something like:

initialize dp[0][0]
initialize dp[0][1...W]
initialize dp[1...n][0]
for (int r = 1; r <= n; r++)
    for (int v = 1; v <= W; v++) {
        dp[r][v] = dp[r - 1][v];
        if (v >= v[r]) dp[r][v] = combine(dp[r - 1][v], dp[r - 1][v - v[r]]);
    }

where v[r] >= 1 for 1 <= r <= n, then, it can be space-optimized to a 1D DP as:

initialize dp[0] (corresponds to previous dp[0][0])
initialize dp[1...W] (corresponds to previous dp[0][1..W])
for (int r = 1; r <= n; r++)
    for (int v = W; v >= v[r]; v--)
        dp[v] = combine(dp[v], dp[v - v[r]])

Since v[r] >= 1 and we are iterating backwards, dp[v] would contain dp[r - 1][v] before the updating and dp[v - v[r]]
would contain dp[r - 1][v - v[r]] since we are iterating backwards and wouldn't have updated dp[v - v[r] yet.

32. If the DP transition looks something like:

initialize dp[0][0]
initialize dp[0][1...W]
initialize dp[1...n][0]
for (int r = 1; r <= n; r++)
    for (int v = 1; v <= W; v++) {
        dp[r][v] = dp[r][v];
        if (v >= v[r])
            dp[r][v] = combine(dp[r][v], dp[r][v - v[r]]);
    }

where v[r] >= 1 for 1 <= r <= n, then, it can be space-optimized to a 1D DP as:

initialize dp[0]        (corresponds to dp[0][0])
initialize dp[1...W]    (corresponds to dp[0][1...W])
for (int r = 1; r <= n; r++)
    for (int v = v[r]; v <= W; v++)
        dp[v] = combine(dp[v], dp[v - v[r]])

Since v[r] >= 1 and we iterate forwards, dp[v] would contain dp[r - 1][v] before the updating, and,
dp[v - v[r]] would be dp[r - 1][v - v[r]] since we would've already updated it (since we are iterating forward).

33. Some DP Lessons:

1. If a problem says "subset of a subset" or "choice inside a choice", both choices must be modeled together in a single DP state.
2. If inner decisions depend on outer decisions, add dimensions.
3. Each item may have multiple logical roles:
i. unused
ii. used in the outer subset
iii. used in both outer and inner subset
4. If dp[r] depends only on dp[r - 1], remove r (state compression)
5. When choices are nested and constrained, model them together, define DP precisely, respect bounds strictly, and compress whenever history is irrelevant.

34. Sliding Range Minimum

Let n, k >= 1
Suppose you have a sequence of values v[1, n]

Suppose, at each step i, starting from 1 and reaching till k, you want

min { v[j] + f(j) | L(i) <= j <= R(i)}
, where, 
1. R(i) increases by exactly 1 as i increases by 1
2. L(i) never decreases as i increases
3. f(j) is a function of j only and does not depend on i

This is the sliding window minimum problem
We solve this using a monotonic deque that maintains the following invariants during each step:

1. The deque stores all the indices which are inside the current window
2. The deque is sorted (in non-decreasing order) from front to the back according
   to the value of (v + f) at the index in the deque

This ensures that the front of the deque contains the index of the minimum of (v + f) inside the current window

deque<int> dq;
for (int i = 1; i <= k; i++) {  
    int right = R(i);
    int left = L(i);

    // insert first
    while (!dq.empty() && (v[dq.back()] + f(dq.back())) >= v[right] + f(right))
        dq.pop_back();
    dq.push_back(right);

    // delete expired elements later
    while (!dq.empty() && dq.front() < left)
        dq.pop_front();

    if (!dq.empty()) {
        int mIdx = dq.front();
        int mVal = v[mIdx] + f(mIdx); // minimum of the window at step i 
    }
}

The updation at each step works in amortized O(1), and the querying at each step works in O(1)



